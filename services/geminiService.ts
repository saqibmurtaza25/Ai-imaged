
import { GoogleGenAI, Modality } from "@google/genai";
import { GenerationOptions } from '../types';
import { API_ASPECT_RATIO_MAP } from '../constants';

const API_KEY = process.env.API_KEY;
if (!API_KEY) {
  throw new Error("API_KEY environment variable is not set");
}

const ai = new GoogleGenAI({ apiKey: API_KEY });

const buildPrompt = (options: GenerationOptions): string => {
  const stylePrompts: { [key: string]: string } = {
    'Realistic': 'photorealistic, dslr photo, high quality, sharp focus',
    'Cinematic': 'cinematic shot, dramatic lighting, wide angle, movie still',
    'Product Shot': 'commercial product photography, clean background, studio lighting',
    'Macro': 'macro photography, 100mm lens, extreme close-up, detailed',
    'Architectural': 'architectural photography, clean lines, wide-angle lens, perfect perspective',
  };

  const basePrompt = `Generate a photorealistic image that looks like it was captured through a professional DSLR camera. The image must have natural lighting, real-world shadows, accurate reflections, and human-eye realism. Do not include any watermark, text overlay, logo, or branding of any kind.`;
  
  return `${options.prompt}, ${stylePrompts[options.style]}, ${options.resolution}, ${basePrompt}`;
};

export const generateImage = async (
  options: GenerationOptions,
  image?: { base64: string; mimeType: string }
): Promise<string> => {
  try {
    if (image) {
      // Image Editing Mode
      const imagePart = {
        inlineData: {
          data: image.base64,
          mimeType: image.mimeType,
        },
      };

      // Combine style and prompt for editing instructions
      const textPart = {
        text: `Style: ${options.style}. Prompt: ${options.prompt}`,
      };

      const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash-image',
        contents: { parts: [imagePart, textPart] },
        config: {
          responseModalities: [Modality.IMAGE],
        },
      });

      const generatedPart = response.candidates?.[0]?.content?.parts?.[0];
      if (generatedPart && generatedPart.inlineData) {
        const base64ImageBytes = generatedPart.inlineData.data;
        const mimeType = generatedPart.inlineData.mimeType;
        return `data:${mimeType};base64,${base64ImageBytes}`;
      } else {
        const fallbackError = response.candidates?.[0]?.finishReason;
        throw new Error( fallbackError ? `Image generation failed: ${fallbackError}` : "No image was edited or generated by the API.");
      }
    } else {
      // Text-to-Image Mode
      const fullPrompt = buildPrompt(options);
      const mappedAspectRatio = API_ASPECT_RATIO_MAP[options.aspectRatio];

      const response = await ai.models.generateImages({
        model: 'imagen-4.0-generate-001',
        prompt: fullPrompt,
        config: {
          numberOfImages: 1,
          outputMimeType: 'image/jpeg',
          aspectRatio: mappedAspectRatio,
        },
      });

      if (response.generatedImages && response.generatedImages.length > 0) {
        const base64ImageBytes = response.generatedImages[0].image.imageBytes;
        return `data:image/jpeg;base64,${base64ImageBytes}`;
      } else {
        throw new Error("No image was generated by the API.");
      }
    }
  } catch (error) {
    console.error("Error with Gemini API:", error);
    if (error instanceof Error) {
        throw new Error(`Failed to process image: ${error.message}`);
    }
    throw new Error("An unknown error occurred while processing the image.");
  }
};
